/**
 * server/agent.js
 * LLM Agent â€” å¯é…ç½®çš„ AI åˆ†æå¼•æ“ï¼Œæ¥å—æ–‡ä»¶å…ƒä¿¡æ¯å¹¶è¿”å›åˆ†ç±»ç»“æœ
 */
import OpenAI from 'openai';
import { loadSettings } from './routes/settings.js';
import { performTavilySearch } from './search.js';

let clientCache = null;
let lastConfig = '';

function getClient() {
    const settings = loadSettings();
    const configKey = `${settings.apiEndpoint}|${settings.apiKey}|${settings.model}`;

    if (clientCache && lastConfig === configKey) {
        return { client: clientCache, model: settings.model };
    }

    clientCache = new OpenAI({
        apiKey: settings.apiKey || 'sk-placeholder',
        baseURL: settings.apiEndpoint || 'https://api.openai.com/v1',
    });
    lastConfig = configKey;
    return { client: clientCache, model: settings.model || 'gpt-4o-mini' };
}

/**
 * Analyze a batch of file entries with LLM.
 * @param {Array} entries - [{name, size, type, path}]
 * @param {string} parentPath - The directory being scanned
 * @returns {Promise<Array>} - Analysis results with classification
 */
export async function analyzeEntries(entries, parentPath) {
    const { client, model } = getClient();

    const entrySummary = entries.map((e, i) =>
        `${i + 1}. [${e.type}] "${e.name}" â€” ${formatSize(e.size)}`
    ).join('\n');

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ“ä½œç³»ç»Ÿä¸ç£ç›˜ç©ºé—´æ¸…ç†ä¸“å®¶ã€‚ä½ éœ€è¦åˆ†æç›®æ ‡æ–‡ä»¶æˆ–ç›®å½•ï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯å¦å¯ä»¥è¢«å®‰å…¨åˆ é™¤ã€‚
ä½ çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹è¯·ä½¿ç”¨ä¸­æ–‡ï¼Œä»¥ä¾¿äºæ—¥å¿—å®¡æŸ¥ã€‚

ğŸš¨ ã€æ ¸å¿ƒè§„åˆ™ã€‘ï¼š
- ç³»ç»Ÿæ–‡ä»¶ï¼ˆWindows, Program Files, é©±åŠ¨, Registry/æ³¨å†Œè¡¨ç›¸å…³ï¼‰ â†’ å¿…é¡»åˆ¤å®šä¸º "keep"
- ç”¨æˆ·æ–‡æ¡£ã€ç…§ç‰‡ã€é‡è¦çš„ä¸ªäººæ•°æ® â†’ å¿…é¡»åˆ¤å®šä¸º "keep"
- ç¼“å­˜(Cache)ã€ä¸´æ—¶æ–‡ä»¶(Temp)ã€æ„å»ºäº§ç‰©(Build artifacts)ã€æ—¥å¿—(Logs)ã€æ—§ä¸‹è½½å†…å®¹ â†’ é€šå¸¸ä¸º "safe_to_delete"
- å¦‚æœä½ é‡åˆ°å®Œå…¨é™Œç”Ÿçš„è½¯ä»¶åç§°æˆ–ç›®å½•åï¼Œä¸”ã€ç»å¯¹æ— æ³•æ ¹æ®ä½ çš„å†…éƒ¨çŸ¥è¯†åº“æ¨æ–­å…¶ç”¨é€”ã€‘ï¼Œä½  å¿…é¡» åˆ¤å®šä¸º "needs_search"ï¼ˆéœ€è¦è”ç½‘ï¼‰ï¼Œè€Œä¸æ˜¯ç²—æš´åœ°çŒœæµ‹ã€‚
- å½“ä½ ä¸ç¡®å®šä¸”éé™Œç”Ÿè½¯ä»¶æ—¶ï¼Œå®å¯åˆ¤å®šä¸º "suspicious"ï¼Œä¹Ÿä¸è¦åˆ¤å®šä¸º "safe_to_delete"

ğŸ’» ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘ï¼š
ä½ å¿…é¡»ä¸”åªèƒ½è¿”å›ä¸€ä¸ªåˆæ³•çš„ JSON æ•°ç»„ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–çš„ Markdown æ–‡æœ¬ã€‚
JSON æ•°ç»„ä¸­çš„æ¯ä¸ªå¯¹è±¡å¿…é¡»ä¸¥æ ¼åŒ…å«ä»¥ä¸‹å­—æ®µï¼ˆKey å¿…é¡»ä¸ºè‹±æ–‡ï¼Œæšä¸¾å€¼å¿…é¡»ä¸¥æ ¼ä¸€è‡´ï¼Œä½†æè¿°æ€§å†…å®¹è¯·ä½¿ç”¨ä¸­æ–‡ï¼‰ï¼š
{
  "index": <æ•°å­—ï¼Œä¸è¾“å…¥å¯¹åº”>,
  "name": "<æ–‡ä»¶å>",
  "classification": "safe_to_delete" | "suspicious" | "keep" | "needs_search", // âš ï¸ å¿…é¡»æ˜¯è¿™å››ä¸ªè‹±æ–‡å­—ç¬¦ä¸²ä¹‹ä¸€
  "purpose": "<ç®€çŸ­çš„ä¸­æ–‡æè¿°ï¼Œè¯´æ˜è¿™ä¸ªæ–‡ä»¶/æ–‡ä»¶å¤¹å¤§æ¦‚æ˜¯åšä»€ä¹ˆç”¨çš„>",
  "reason": "<è¯¦ç»†çš„ä¸­æ–‡ç†ç”±ï¼Œè§£é‡Šä¸ºä»€ä¹ˆå®ƒå¯ä»¥/ä¸èƒ½è¢«åˆ é™¤ï¼ˆæˆ–éœ€è¦æœç´¢çš„åŸå› ï¼‰>",
  "risk": "low" | "medium" | "high" // âš ï¸ å¿…é¡»æ˜¯è¿™ä¸‰ä¸ªè‹±æ–‡å­—ç¬¦ä¸²ä¹‹ä¸€ï¼Œåˆ†åˆ«ä»£è¡¨ä½ã€ä¸­ã€é«˜é£é™©
}`;

    const userPrompt = `è¯·åˆ†æä»¥ä¸‹ä½äºç›®å½• "${parentPath}" ä¸­çš„é¡¹ç›®ï¼š

${entrySummary}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚è¿”å› JSON æ•°ç»„ã€‚`;

    const startTime = Date.now();

    try {
        const response = await client.chat.completions.create({
            model,
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: userPrompt },
            ],
            temperature: 0.1,
        });

        const elapsed = Date.now() - startTime;
        let content = response.choices[0].message.content || '';
        // DeepSeek reasoner models may include reasoning_content
        const reasoning = response.choices[0].message.reasoning_content || '';

        let tokenUsage = {
            prompt: response.usage?.prompt_tokens || 0,
            completion: response.usage?.completion_tokens || 0,
            total: response.usage?.total_tokens || 0,
        };

        // Extract JSON from markdown if present
        let cleanContent = content.trim();
        if (cleanContent.startsWith('```json')) {
            cleanContent = cleanContent.replace(/^```json/, '').replace(/```$/, '').trim();
        } else if (cleanContent.startsWith('```')) {
            cleanContent = cleanContent.replace(/^```/, '').replace(/```$/, '').trim();
        }

        const parsed = JSON.parse(cleanContent);
        let results = Array.isArray(parsed) ? parsed : (parsed.results || parsed.items || parsed.analysis || [parsed]);

        const settings = loadSettings();

        let needSearchItems = results.filter(r => r.classification === 'needs_search');

        // Follow-up PASS for needs_search
        if (needSearchItems.length > 0) {
            if (settings.enableWebSearch && settings.tavilyApiKey) {
                // Fetch search context (Run serially to not bomb API immediately)
                let searchPrompts = [];
                for (let r of needSearchItems) {
                    const summary = await performTavilySearch(r.name, settings.tavilyApiKey);
                    if (summary) {
                        searchPrompts.push(`- æ–‡ä»¶/ç›®å½• "${r.name}": ${summary}`);
                    } else {
                        searchPrompts.push(`- æ–‡ä»¶/ç›®å½• "${r.name}": æœç´¢å¼•æ“æ— æ˜ç¡®ä¿¡æ¯`);
                    }
                }

                const secondPassPrompt = `è¿™æ˜¯æ ¹æ®ä½ è¦æ±‚æä¾›çš„è”ç½‘æœç´¢è¡¥å……ä¿¡æ¯ï¼š\n\n${searchPrompts.join('\n')}\n\nè¯·ç»“åˆè¿™äº›ç½‘é¡µä¿¡æ¯ï¼Œä¸ºä½ ä¹‹å‰åˆ¤å®šä¸º 'needs_search' çš„é¡¹ç›®ç»™å‡ºæœ€ç»ˆç»“è®ºã€‚\nè¾“å‡ºæ ¼å¼ä¸ä¹‹å‰å®Œå…¨ä¸€è‡´çš„ JSON æ•°ç»„ï¼Œä½† classification åªèƒ½ä» "safe_to_delete" | "suspicious" | "keep" ä¸­é€‰æ‹©ã€‚`;

                const response2 = await client.chat.completions.create({
                    model,
                    messages: [
                        { role: 'system', content: systemPrompt },
                        { role: 'user', content: userPrompt },
                        { role: 'assistant', content: cleanContent },
                        { role: 'user', content: secondPassPrompt }
                    ],
                    temperature: 0.1,
                });

                let content2 = response2.choices[0].message.content || '';
                let cleanContent2 = content2.trim();
                if (cleanContent2.startsWith('```json')) cleanContent2 = cleanContent2.replace(/^```json/, '').replace(/```$/, '').trim();
                else if (cleanContent2.startsWith('```')) cleanContent2 = cleanContent2.replace(/^```/, '').replace(/```$/, '').trim();

                const parsed2 = JSON.parse(cleanContent2);
                let secondaryResults = Array.isArray(parsed2) ? parsed2 : (parsed2.results || parsed2.items || parsed2.analysis || [parsed2]);

                // Merge Results
                for (let sr of secondaryResults) {
                    const targetIdx = results.findIndex(original => original.index === sr.index);
                    if (targetIdx !== -1) {
                        results[targetIdx] = sr;
                    }
                }

                tokenUsage.prompt += response2.usage?.prompt_tokens || 0;
                tokenUsage.completion += response2.usage?.completion_tokens || 0;
                tokenUsage.total += response2.usage?.total_tokens || 0;

            } else {
                // Feature off or no key - automatically downgrade to suspicious
                for (let r of needSearchItems) {
                    r.classification = 'suspicious';
                    r.reason += ' (Web Search disabled, downgraded to suspicious)';
                }
            }
        }

        return {
            results: Array.isArray(results) ? results : [results],
            tokenUsage,
            trace: {
                model,
                systemPrompt,
                userPrompt,
                reasoning,
                rawContent: content,
                elapsed: Date.now() - startTime,
                error: null,
            },
        };
    } catch (err) {
        const elapsed = Date.now() - startTime;
        console.error('[Agent] LLM analysis failed:', err.message);
        // Fallback: mark everything as suspicious
        return {
            results: entries.map((e, i) => ({
                index: i + 1,
                name: e.name,
                classification: 'suspicious',
                purpose: 'Analysis failed â€” manual review recommended',
                reason: err.message,
                risk: 'high',
            })),
            tokenUsage: { prompt: 0, completion: 0, total: 0 },
            trace: {
                model,
                systemPrompt,
                userPrompt,
                reasoning: '',
                rawContent: '',
                elapsed,
                error: err.message,
            },
        };
    }
}

/**
 * Verifies if a directory is truly safe to delete by examining its contents.
 * @param {string} dirName - Name of the directory
 * @param {Array} entries - Its child entries
 * @param {string} parentPath - Directory's absolute path
 */
export async function verifyDirectoryDelete(dirName, entries, parentPath) {
    const { client, model } = getClient();

    const entrySummary = entries.map((e, i) =>
        `${i + 1}. [${e.type}] "${e.name}" â€” ${formatSize(e.size)}`
    ).join('\n');

    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ“ä½œç³»ç»Ÿä¸ç£ç›˜ç©ºé—´æ¸…ç†ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹ä¸€ä¸ª**åˆæ­¥åˆ¤å®šå¯ä»¥åˆ é™¤**çš„æ–‡ä»¶å¤¹è¿›è¡Œã€äºŒæ¬¡ç¡®è®¤æ ¸æŸ¥ã€‘ã€‚
ä½ çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹è¯·ä½¿ç”¨ä¸­æ–‡ï¼Œä»¥ä¾¿äºæ—¥å¿—å®¡æŸ¥ã€‚

ğŸš¨ ã€ä»»åŠ¡è§„åˆ™ã€‘ï¼š
ä¸‹é¢ç”¨æˆ·ä¼šæä¾›è¯¥æ–‡ä»¶å¤¹å†…éƒ¨åŒ…å«çš„æ–‡ä»¶æˆ–ç›®å½•ç»“æ„æ‘˜è¦ã€‚è¯·ä»”ç»†å®¡æŸ¥è¿™äº›å†…å®¹ï¼š
å¦‚æœå…¶ä¸­åŒ…å«ä»»ä½•çœ‹ä¼¼é‡è¦çš„æ•°æ®ï¼ˆå¦‚ç³»ç»Ÿç›¸å…³æ–‡ä»¶ã€é‡è¦æºä»£ç ã€ä¸ªäººçš„å›¾ç‰‡/æ–‡æ¡£ã€ç¯å¢ƒé…ç½®ç­‰ï¼‰ï¼Œä½ å¿…é¡»åˆ¤å®šæ•´ä¸ªæ–‡ä»¶å¤¹ã€ä¸å¯æ•´ä½“åˆ é™¤ã€‘ã€‚
åªæœ‰å½“é‡Œé¢çš„å†…å®¹çº¯ç²¹æ˜¯æ— ç”¨çš„ç¼“å­˜ï¼ˆCacheï¼‰ã€æ—§ä¸­é—´äº§ç‰©ï¼ˆArtifactsï¼‰ã€æ—¥å¿—ï¼ˆLogsï¼‰ã€ç©ºæ–‡ä»¶å¤¹æˆ–ä¸´æ—¶æ–‡ä»¶ç­‰ï¼Œä½ æ‰èƒ½åˆ¤å®šä¸ºã€å¯ä»¥æ•´ä½“åˆ é™¤ã€‘ã€‚

ğŸ’» ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘ï¼š
ä½ å¿…é¡»ä¸”åªèƒ½è¿”å›ä¸€ä¸ªåˆæ³•çš„ JSON å¯¹è±¡ï¼Œä¸è¦å«æœ‰å…¶å®ƒ Markdown æ–‡æœ¬ï¼š
{
  "safe": true | false, // å¸ƒå°”å€¼è¡¨ç¤ºèƒ½å¦æ•´ä½“åˆ é™¤
  "reason": "<è¯¦ç»†çš„ä¸­æ–‡ç†ç”±ï¼Œè§£é‡Šä¸ºä»€ä¹ˆåˆ¤å®šå®ƒå®‰å…¨æˆ–ä¸å®‰å…¨>"
}`;

    const userPrompt = `æˆ‘ä»¬è¦äºŒæ¬¡ç¡®è®¤æ–‡ä»¶å¤¹ "${dirName}"ï¼ˆä½äº "${parentPath}"ï¼‰èƒ½å¦æ•´ä½“å®‰å…¨åˆ é™¤ã€‚
ä»¥ä¸‹æ˜¯å®ƒå†…éƒ¨åŒ…å«çš„æ–‡ä»¶æ‘˜è¦ï¼š

${entrySummary.length > 0 ? entrySummary : "(è¯¥æ–‡ä»¶å¤¹å½“å‰ä¸ºç©º)"}

è¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¿”å›éªŒè¯ç»“æœã€‚`;

    const startTime = Date.now();

    try {
        const response = await client.chat.completions.create({
            model,
            messages: [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: userPrompt },
            ],
            temperature: 0.1,
        });

        const elapsed = Date.now() - startTime;
        let content = response.choices[0].message.content || '';
        const reasoning = response.choices[0].message.reasoning_content || '';

        let cleanContent = content.trim();
        if (cleanContent.startsWith('```json')) {
            cleanContent = cleanContent.replace(/^```json/, '').replace(/```$/, '').trim();
        } else if (cleanContent.startsWith('```')) {
            cleanContent = cleanContent.replace(/^```/, '').replace(/```$/, '').trim();
        }

        const parsed = JSON.parse(cleanContent);

        const tokenUsage = {
            prompt: response.usage?.prompt_tokens || 0,
            completion: response.usage?.completion_tokens || 0,
            total: response.usage?.total_tokens || 0,
        };

        return {
            safe: !!parsed.safe,
            reason: parsed.reason || '',
            tokenUsage,
            trace: {
                model,
                systemPrompt,
                userPrompt,
                reasoning,
                rawContent: content,
                elapsed,
                error: null,
            }
        };
    } catch (err) {
        const elapsed = Date.now() - startTime;
        console.error('[Agent] Directory verification failed:', err.message);
        return {
            safe: false,
            reason: 'éªŒè¯å¤±è´¥ï¼š' + err.message,
            tokenUsage: { prompt: 0, completion: 0, total: 0 },
            trace: {
                model: 'gpt-4o-mini',
                systemPrompt,
                userPrompt,
                reasoning: '',
                rawContent: '',
                elapsed,
                error: err.message,
            }
        };
    }
}

function formatSize(bytes) {
    if (bytes < 1024) return `${bytes} B`;
    if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(1)} KB`;
    if (bytes < 1024 * 1024 * 1024) return `${(bytes / (1024 * 1024)).toFixed(1)} MB`;
    return `${(bytes / (1024 * 1024 * 1024)).toFixed(2)} GB`;
}
